import sys
from pathlib import Path
import re
from collections import Counter

from mcp.server.stdio import stdio_server
from mcp.server.lowlevel import Server
import mcp.types as types
import anyio

# Known logging patterns taken from SwiftBindings used to 
# identify messages in the logs.
# These are not exhaustive and may need to be updated.
known_tooling_issues = {
    "protocol_conformance": {
        "description": "Protocol Conformance Issues",
        "regex": r"Protocol conformance descriptor not found"
    },
    "unsupported_signature": {
        "description": "Unsupported Types/Signatures",
        "regex": r"has unsupported signature|unsupported generic parameters"
    },
    "property_processing": {
        "description": "Property Processing Failures",
        "regex": r"Couldn't process property"
    },
    "module_dependency": {
        "description": "Module Dependency Issues",
        "regex": r"Type should have been processed in a previous module"
    },
    "unsupported_node": {
        "description": "Unsupported Node Types",
        "regex": r"Unsupported node kind"
    },
    "generic_type_not_supported": {
        "description": "Generic Type Not Supported",
        "regex": r"Generic type .* not supported"
    },
    "metadata_accessor": {
        "description": "Missing Metadata Accessors",
        "regex": r"Metadata accessor not found"
    }
}

# # Define available prompts
# PROMPTS = {
#     "find-logs": types.Prompt(
#         name="find-logs",
#         description="Find logs generated by SwiftBindings",
#         arguments=[
#             types.PromptArgument(
#                 name="framework-name",
#                 description="The name of the Swift framework which was used to generate the bindings",
#                 required=True
#             )
#         ],
#     ),
# }



def check_and_update_log_cache(log_path: str, cache: dict) -> str:
    """
    Check if the log file is already in the cache. If not, read it and add it to the cache.

    Args:
        log_path (str): The path to the log file.
        cache (dict): The cache dictionary to store log content.
    Returns:
        str: The content of the log file.
    """
    # Read the log file
    log_path = Path(log_path)
    if not log_path.is_file():
        raise ValueError(f"{log_path} is not a valid file.")
    
    if log_path in cache:
        return cache[log_path]
    else:
        log_content = log_path.read_text(encoding="utf-8", errors="ignore")

        # Check if the log content is empty
        if not log_content:
            raise ValueError(f"{log_path} is empty.")
    
        # Normalize log content
        log_content = log_content.replace("\r\n", "\n")  # Normalize line endings
        log_content = log_content.replace("\r", "\n")  # Normalize line endings
        log_content = log_content.replace("\n\n", "\n")  # Remove extra newlines

        # Add to cache
        cache[log_path] = log_content

        return cache[log_path]
    

def generate_summary_report(component_data):    
    # Overview section
    markdown = "# Swift Bindings Log Summary Report\n\n"
    markdown += "## Overview\n"
    markdown += "This log shows the process of generating bindings\n\n"
    
    # Component summary table
    markdown += "## Component Summary\n\n"
    markdown += "| Component | Levels | Key Issues |\n"
    markdown += "|-----------|--------|------------|\n"
    
    # Sort components by total count across all levels
    sorted_components = sorted(
        component_data.items(),
        key=lambda x: sum(x[1]["levels"].values()),
        reverse=True
    )
    
    for component, data in sorted_components:
        # Format level counts
        levels_str = ", ".join([f"{level}: {count}" for level, count in data["levels"].most_common()])
        
        # Format issues
        issues = data["issues"]
        issue_str = ", ".join([known_tooling_issues[issue]["description"] for issue, count in issues.most_common(3)]) if issues else "None"
        
        markdown += f"| `{component}` | {levels_str} | {issue_str} |\n"
    
    # Aggregate all issues for the common issues section
    all_issues = Counter()
    for component, data in component_data.items():
        all_issues.update(data["issues"])
    
    # Common issues section
    markdown += "\n## Common Issues\n\n"
    
    for i, (issue, count) in enumerate(all_issues.most_common(7), 1):
        desc = known_tooling_issues[issue]["description"]
        markdown += f"{i}. **{desc}** ({count} occurrences):\n"
    
    return markdown

def process_log(log_content: str) -> dict:
    """
    Process the log content generated by SwiftBindings and extract component data.

    Args:
        log_content (str): The log content as a string.
    """

    # Store data by component
    component_data = {}
    
    # Parse log entries - handle both timestamp and non-timestamp formats
    level_component_pattern = re.compile(r'(?:(\d{4}-\d{2}-\d{2}T[\d:.]+Z)\s+)?(\w+):\s+([^\[]+)\[\d+\]')
    message_pattern = re.compile(r'^(?:(\d{4}-\d{2}-\d{2}T[\d:.]+Z)\s+)?(.*)')
    
    lines = log_content.split('\n')
    i = 0
    
    # Add debug counters
    components_found = 0
    messages_found = 0
    issues_found = 0
    
    while i < len(lines):
        # Look for level/component line
        level_match = level_component_pattern.match(lines[i])
        if level_match:
            groups = level_match.groups()
            if groups[0]:  # Timestamp is present
                _, level, component = groups
            else:  # No timestamp
                level, component = groups[1:]
            component = component.strip()  # Remove any trailing whitespace
            components_found += 1
            
            # Check if next line contains the message
            message = ""
            if i + 1 < len(lines):
                message_match = message_pattern.match(lines[i+1])
                if message_match:
                    groups = message_match.groups()
                    if groups[0]:  # Timestamp is present
                        _, message = groups
                    else:  # No timestamp
                        message = groups[1:]
                    
                    message = message_match.group(2).strip()
                    messages_found += 1
                    i += 1  # Skip the message line in the next iteration
            
            # Initialize component data if needed
            if component not in component_data:
                component_data[component] = {
                    "levels": Counter(),
                    "issues": Counter()
                }
            
            # Count the log level
            component_data[component]["levels"][level] += 1
            
            # Check for issues in the message
            for issue_type, issue_data in known_tooling_issues.items():
                issue_pattern = issue_data["regex"]
                if re.search(issue_pattern, message):
                    component_data[component]["issues"][issue_type] += 1
                    issues_found += 1
                    break
        i += 1
    
    # Print debug info
    print(f"Components found: {components_found}")
    print(f"Messages found: {messages_found}")
    print(f"Issues matched: {issues_found}")
    print(f"Unique components: {len(component_data)}")

    # Print the component data for debugging
    for component, data in component_data.items():
        print(f"Component: {component}")
        print(f"Levels: {data['levels']}")
        print(f"Issues: {data['issues']}")
    
    return component_data

def read_and_parse_log(log_path: str, cache: dict) -> str:
    """
    Read the log file and parse its content.
    Generate a summary report of the log file.

    Args:
        log_path (str): The path to the log file.
        cache (dict): The cache dictionary to store log content.
    """

    log_content = check_and_update_log_cache(log_path, cache)
    
    # Call the parsing function
    component_data = process_log(log_content)
    
    # Generate a summary report
    report = generate_summary_report(component_data)

    return report

def is_present_in_log(log_path: str, message: str, cache: dict) -> bool:
    """
    Check if a specific message is present in the log file.

    Args:
        log_path (str): The path to the log file.
        message (str): The message to search for.
        cache (dict): The cache dictionary to store log content.
    Returns:
        bool: True if the message is found, False otherwise.
    """
    log_content = check_and_update_log_cache(log_path, cache)
    
    return message in log_content

def main():
    app = Server("LogParser", instructions="Parse Swift bindings log files.")
    # Define a cache for read logs
    LOG_CACHE = {}

    @app.call_tool()
    async def handle_call_tool(
        name: str, arguments: dict
    ) -> list[types.TextContent]:
        if name == "read_and_parse_log":
            log_path = arguments.get("log_path", "")
            if not log_path:
                raise ValueError("Log path is required.")
            
            report = read_and_parse_log(log_path, LOG_CACHE)

            log_content = check_and_update_log_cache(log_path, LOG_CACHE)

            # Create enhanced prompt with parsed data
            prompt = f"""
        You are a log analysis assistant that provides insights into code generation logs. 
        You specialize in extracting logged patterns emitted by SwiftBindings tool.

        Your task it to analyze log file generated by SwiftBindings tool. 
        I've already parsed the statistical data, but I need you to provide both generalized and 
        specific examples of the issues found in this specific log file.

        !!!Do not change the values of the computed statistics I provided. Include all the computed
        statistics in your response.!!!
         
        The statistics are:

        {report}

        ### For your response:
        For each issue type in the Common Issues table, find corresponding examples in the log file and provide them in two forms:
       
        - Generalized form: For example, if the log contains multiple instances of the same issue with different types,
        you should generalize them. For instance:
            - "Error caused by: Type 'int' not supported"
            - "Error caused by: Type 'string' not supported"
            You should provide them as:
            - "Error caused by: Type <T> not supported"

            Example of good generalization for some common issues:
            - "Protocol conformance descriptor not found for type X and protocol Y"
            - "Method X has unsupported signature"
            - "PropertyHandler: Couldn't process property X of type Y."
            - "Generic type <T> not supported."
            - "Metadata accessor not found for type X"
            

        - Specific form: For each generalized example, provide one or two specific examples from the log file.
        You should copy the examples directly from log file without any modifications.

        !!!Ensure that all examples are directly taken from the log file and do not invent new examples.!!!

        !!!Do not reason about the examples and what is causing them!!! 

        Response should be in markdown format.

        Log content:
        {log_content}
        """
            
            return [types.TextContent(type="text", text=prompt)]
        elif name == "list_files":
            directory = arguments.get("directory", ".")
            if not Path(directory).is_dir():
                raise ValueError(f"{directory} is not a valid directory.")
            
            files = [str(file) for file in Path(directory).iterdir() if file.is_file()]
            return [types.TextContent(type="text", text="\n".join(files))]
        elif name == "is_present_in_log":
            log_path = arguments.get("log_path", "")
            message = arguments.get("message", "")
            if not log_path or not message:
                raise ValueError("Log path and message are required.")
            
            present = is_present_in_log(log_path, message, LOG_CACHE)
            return [types.TextContent(type="text", text=str(present))]

    @app.list_tools()
    async def list_tools() -> list[types.Tool]:
        """List all available tools."""
        
        return [
            types.Tool(
                name="read_and_parse_log",
                description=(
                    "Open a log file generated by SwiftBindings, read its content,\n"
                    "preprocess, and extract component data.\n"
                    "Finally, generate a summary report of the log file.\n"
                ),
                inputSchema={
                    "type": "object",
                    "properties": {
                        "log_path": {
                            "type": "string",
                            "description": "Path to the log file.",
                        },
                    },
                    "required": ["log_path"],
                },
            ),
            types.Tool(
                name="list_files",
                description=(
                    "List all files in the project directory."
                ),
                inputSchema={
                    "type": "object",
                    "properties": {
                        "directory": {
                            "type": "string",
                            "description": "Directory to list files from.",
                        },
                    },
                    "required": ["directory"],
                },
            ),
            types.Tool(
                name="is_present_in_log",
                description=(
                    "Check if a specific message is present in the log file."
                ),
                inputSchema={
                    "type": "object",
                    "properties": {
                        "log_path": {
                            "type": "string",
                            "description": "Path to the log file.",
                        },
                        "message": {
                            "type": "string",
                            "description": "Message to search for.",
                        },
                    },
                    "required": ["log_path", "message"],
                },
            ),
        ]
    
    # @app.list_prompts()
    # async def list_prompts() -> list[types.Prompt]:
    #     return list(PROMPTS.values())

    async def arun():
        async with stdio_server() as streams:
            await app.run(
                streams[0], streams[1], app.create_initialization_options()
            )

    anyio.run(arun)

    return 0

if __name__ == "__main__":
    sys.exit(main())